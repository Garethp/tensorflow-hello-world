# Glossary
This is just a list of words that I think might be useful for a programmer trying to learn about neural networks to
refer to now and then.

 * Cross-Entropy
  * A calculation of how far the predicated outcome is from the actual outcome
 * Dropout
  * A technique of randomly turning off neurons during the training process as a way of trying to prevent overfitting
 * Matrix
  * An array of numbers
 * Overfitting
  * When a neural network is trained on a set of data and becomes to specialised on that particular set. It may be
  completely accurate for that particular set of data, but wildly miss the mark for any data is hasn't seen yet.